(window.webpackJsonp=window.webpackJsonp||[]).push([[83],{502:function(a,s,t){"use strict";t.r(s);var e=t(2),r=Object(e.a)({},(function(){var a=this,s=a._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h2",{attrs:{id:"前言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[a._v("#")]),a._v(" 前言")]),a._v(" "),s("p",[a._v("官方镜像下载地址: "),s("a",{attrs:{href:"https://www.centos.org/download/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Centos"),s("OutboundLink")],1),a._v("，"),s("a",{attrs:{href:"http://www.apache.org/dyn/closer.cgi/hadoop/common/",target:"_blank",rel:"noopener noreferrer"}},[a._v("hadoop"),s("OutboundLink")],1),a._v("，"),s("a",{attrs:{href:"https://www.oracle.com/java/technologies/downloads/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Java"),s("OutboundLink")],1),a._v("\nCentos为"),s("a",{attrs:{href:"http://mirrors.aliyun.com/centos/7.9.2009/isos/x86_64/",target:"_blank",rel:"noopener noreferrer"}},[a._v("CentOS-7-x86_64-DVD-2009"),s("OutboundLink")],1),a._v("\nHadoop为"),s("a",{attrs:{href:"https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/stable/hadoop-3.3.1.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[a._v("hadoop-3.3.1.tar.gz"),s("OutboundLink")],1),a._v("\nJava为"),s("a",{attrs:{href:"https://www.oracle.com/java/technologies/downloads/#java8",target:"_blank",rel:"noopener noreferrer"}},[a._v("jdk-8u301-linux-x64.tar.gz"),s("OutboundLink")],1),a._v("\nPS：Hadoop3.X Java最低版本为1.8\n纯原生态安装，非CDH和HDP，或是Ambari")]),a._v(" "),s("h2",{attrs:{id:"预先设置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#预先设置"}},[a._v("#")]),a._v(" 预先设置")]),a._v(" "),s("p",[a._v("修改主机名hostname")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("hostnamectl set-hostname docloud001.dataojo.com\n")])])]),s("p",[a._v("修改/etc/hosts文件,host文件用户映射ip，docloud001.dataojo.com会解析成当前主机")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[a._v("vi")]),a._v(" /etc/hosts\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 这里我除了修改127.0.0.1里的localhost localhost.localdomain")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("127.0")]),a._v(".0.1   localhost localhost.docloud001.dataojo.com localhost4 localhost4.localdomain4\n::1         localhost localhost.docloud001.dataojo.com localhost6 localhost6.localdomain6\n")])])]),s("blockquote",[s("p",[a._v("重启服务器")])]),a._v(" "),s("h3",{attrs:{id:"关闭防火墙"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关闭防火墙"}},[a._v("#")]),a._v(" 关闭防火墙")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 关闭")]),a._v("\nsystemctl stop firewalld\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 禁止开机自启")]),a._v("\nsystemctl disable firewalld\n")])])]),s("h3",{attrs:{id:"创建hadoop用户"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#创建hadoop用户"}},[a._v("#")]),a._v(" 创建hadoop用户")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 创建用户并使用 /bin/bash 作为shell")]),a._v("\n "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("useradd")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-m")]),a._v(" hadoop "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-s")]),a._v(" /bin/bash\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 给hadoop用户设置密码，若提示密码无效，不用管，接着输入一次即可")]),a._v("\n "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("passwd")]),a._v(" hadoop\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 给hadoop增加执行权限")]),a._v("\n visudo\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#98行  输入 :98 跳转至98行，增加一行 hadoop  ALL=(ALL) ALL")]),a._v("\n root "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("ALL")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("ALL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" ALL\n hadoop "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("ALL")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("ALL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" ALL\n")])])]),s("h3",{attrs:{id:"ssh安装免密登陆"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ssh安装免密登陆"}},[a._v("#")]),a._v(" SSH安装免密登陆")]),a._v(" "),s("h4",{attrs:{id:"单机免密登陆-linux配置ssh免密登录"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#单机免密登陆-linux配置ssh免密登录"}},[a._v("#")]),a._v(" 单机免密登陆——linux配置ssh免密登录")]),a._v(" "),s("p",[a._v("检查是否安装SSH")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("systemctl status sshd\n")])])]),s("p",[a._v("已安装会显示ssh服务的状态(actving)，否则，执行下面命令安装")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -y表示全部同意，不用每次都按y")]),a._v("\nyum "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("install")]),a._v(" openssh-clients "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-y")]),a._v("\nyum "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("install")]),a._v(" openssh-server "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-y")]),a._v("\n")])])]),s("p",[a._v("测试是否可用")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#按提示确认连接后，输入当前用户密码即可，初始没有密码会提示创建密码")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("ssh")]),a._v(" localhost\n")])])]),s("p",[a._v("设置无密码登录")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#~ 代表的是用户的主文件夹，即 “/home/用户名” 这个目录，如你的用户名为 hadoop，则 ~ 就代表 “/home/hadoop/”")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" ~/.ssh/                     "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 若没有该目录，请先执行一次ssh localhost")]),a._v("\nssh-keygen "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-t")]),a._v(" rsa              "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 会有提示，都按回车就可以")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("cat")]),a._v(" id_rsa.pub "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">>")]),a._v(" authorized_keys  "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 加入授权")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("chmod")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("600")]),a._v(" ./authorized_keys    "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 修改文件权限")]),a._v("\n")])])]),s("p",[a._v("此时再用 ssh localhost 命令，无需输入密码就可登陆")]),a._v(" "),s("h2",{attrs:{id:"安装hadoop-3-3-0-tar-gz"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安装hadoop-3-3-0-tar-gz"}},[a._v("#")]),a._v(" 安装Hadoop-3.3.0.tar.gz")]),a._v(" "),s("p",[a._v("上传至服务器，或者从服务器中下载\n找个目录解压，比如/opt下")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# -C 是指定解压目录")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("tar")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-zxvf")]),a._v(" hadoop-3.3.0.tar.gz "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-C")]),a._v(" /opt\n")])])]),s("p",[a._v("解压完检查hadoop是否可用")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#切换到hadoop的安装目录执行, 成功则显示版本信息")]),a._v("\n "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /opt/hadoop-3.3.0\n \n ./bin/hadoop version\n")])])]),s("p",[s("img",{attrs:{src:"https://raw.githubusercontent.com/lichengcan/images/main/1698216447035.jpg",alt:""}})]),a._v(" "),s("p",[a._v("可能会出现这些问题，在vim ~/.bashrc添加：")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("export HADOOP_HOME=/opt/hadoop-3.3.4\nexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nexport HADOOP_COMMON_HOME=$HADOOP_HOME\nexport HADOOP_HDFS_HOME=$HADOOP_HOME\nexport HADOOP_YARN_HOME=$HADOOP_HOME\nexport HADOOP_MAPRED_HOME=$HADOOP_HOME\n")])])]),s("p",[a._v("这里我们可以将hadoop也加入环境变量，就不需要每次到bin目录下执行")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 编辑profile文件")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("vi")]),a._v(" /etc/profile\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 增加hadoop环境变量")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/opt/hadoop-3.3.4\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")])]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$PATH")]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/bin:"),s("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/sbin\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 保存后刷新下环境变量")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("source")]),a._v(" /etc/profile\n")])])]),s("h2",{attrs:{id:"运行"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#运行"}},[a._v("#")]),a._v(" 运行")]),a._v(" "),s("h3",{attrs:{id:"伪分布式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#伪分布式"}},[a._v("#")]),a._v(" 伪分布式")]),a._v(" "),s("h4",{attrs:{id:"_1-修改配置文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-修改配置文件"}},[a._v("#")]),a._v(" 1.修改配置文件")]),a._v(" "),s("p",[a._v("Hadoop 的配置文件位于 "),s("strong",[a._v("安装目录")]),a._v("下 /etc/hadoop/ 中")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@hadoop1 hadoop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# pwd")]),a._v("\n/opt/hadoop-3.3.0/etc/hadoop\n")])])]),s("p",[a._v("伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#修改配置文件hadoop-env.sh")]),a._v("\n\n "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# set to the root of your Java installation")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("JAVA_HOME")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/usr/java/jdk\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#修改配置文件 core-site.xml")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("configuration"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\t"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("--指定Hadoop运行时产生文件的存储目录--"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hadoop.tmp.dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("/opt/data/hadoop/tmp"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("--指定HDFS中NameNode的地址--"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("fs.defaultFS"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hdfs://docloud001.dataojo.com:900"),s("span",{pre:!0,attrs:{class:"token operator"}},[s("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("0")]),a._v("<")]),a._v("/value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/configuration"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#修改配置文件 hdfs-site.xml, ")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#搭建集群后，hadoop本身自带了一个webUI访问页面")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("configuration"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("dfs.replication"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token operator"}},[s("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("1")]),a._v("<")]),a._v("/value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/configuration"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])])]),s("h4",{attrs:{id:"_2-格式化namenode"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-格式化namenode"}},[a._v("#")]),a._v(" 2.格式化NameNode")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("./bin/hdfs namenode "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-format")]),a._v("\n")])])]),s("h4",{attrs:{id:"_3-开启-nanenode-和-datanode-进程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-开启-nanenode-和-datanode-进程"}},[a._v("#")]),a._v(" 3.开启 NaneNode 和 DataNode 进程")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("./sbin/start-dfs.sh\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#启动完成后，可以通过命令 jps 来判断是否成功启动")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("hadoop@localhost hadoop-3.3.0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" jps\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("32081")]),a._v(" NameNode\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("32561")]),a._v(" Jps\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("32234")]),a._v(" DataNode\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#停止")]),a._v("\n./sbin/stop-dfs.sh\n")])])]),s("p",[a._v("如果出现\nERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.\n解决方法：")]),a._v(" "),s("blockquote",[s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" /opt/hadoop-3.3.0/etc/hadoop\n"),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" /hadoop-env.sh\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HDFS_NAMENODE_USER")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("root\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HDFS_DATANODE_USER")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("root\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HDFS_SECONDARYNAMENODE_USER")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("root\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("YARN_RESOURCEMANAGER_USER")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("root\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("YARN_NODEMANAGER_USER")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("root\n")])])])]),a._v(" "),s("p",[a._v("日志文件输出在 安装目录下的logs文件夹中。\n可以访问web页面，前面配置过的 http://localhost:9870/")]),a._v(" "),s("h4",{attrs:{id:"_4-操作集群"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-操作集群"}},[a._v("#")]),a._v(" 4. 操作集群")]),a._v(" "),s("ol",[s("li",[a._v("在HDFS系统上创建一个input文件夹")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("./bin/hdfs dfs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-mkdir")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-p")]),a._v(" /user/test/input\n")])])]),s("ol",[s("li",[a._v("将测试文件内容上传到文件系统上")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("./bin/hdfs dfs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-put")]),a._v(" input/core-site.xml  /user/test/input/\n")])])]),s("ol",[s("li",[a._v("查看上传的文件是否正确")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("./bin/hdfs dfs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-ls")]),a._v(" /user/test/input/\n\n./bin/hdfs dfs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-cat")]),a._v(" /user/test/input/core-site.xml\n")])])]),s("ol",[s("li",[a._v("运行mapReduce程序")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount /user/test/input/core-site.xml /user/test/output/\n\n./bin/hdfs dfs "),s("span",{pre:!0,attrs:{class:"token parameter variable"}},[a._v("-cat")]),a._v(" /user/test/output/*\n")])])]),s("p",[a._v("在浏览器中查看：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://raw.githubusercontent.com/lichengcan/images/main/Snipaste_2023-10-25_10-00-50.jpg",alt:""}})])])}),[],!1,null,null,null);s.default=r.exports}}]);